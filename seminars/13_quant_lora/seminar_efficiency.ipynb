{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ijc-8MXn-edO"
      },
      "source": [
        "## –°–µ–º–∏–Ω–∞—Ä 13: Efficiency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jL3TJmvIe4w",
        "tags": []
      },
      "source": [
        "## –ü–ª–∞–Ω\n",
        "\n",
        "1. Factorization: Low-Rank Adaptation (LoRA)\n",
        "2. Distillation: (Hinton KD, Zagoruyko AT)\n",
        "3. Quantization: AWQ, AQLM, bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwuOqj2hZkPi",
        "tags": []
      },
      "source": [
        "## 0. –ö–ª—é—á–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce06PFv0aF3o"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate evaluate datasets peft bitsandbytes wandb -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEupTwf3ZkPi",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "%config InlineBackend.figure_format='retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZz7N_OqljtV"
      },
      "outputs": [],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAeWcsvLF2_6",
        "tags": []
      },
      "source": [
        "## 1. Factorization: Low-Rank Adaptation (LoRA)\n",
        "\n",
        "–í —ç—Ç–æ–º –±–ª–æ–∫–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [LoRA](https://arxiv.org/abs/2106.09685) –∏–∑ ü§ó PEFT –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –º–æ–¥–µ–ª–∏ SegFormer –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –Ω–µ–±–æ–ª—å—à—É—é –¥–æ–ª—é –∏—Å—Ö–æ–¥–Ω—ã—Ö –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "LoRA –¥–æ–±–∞–≤–ª—è–µ—Ç –Ω–∏–∑–∫–æ—Ä–∞–Ω–≥–æ–≤—ã–µ \"–º–∞—Ç—Ä–∏—Ü—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è\" –∫ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º –±–ª–æ–∫–∞–º –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (–≤ –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –∫ –±–ª–æ–∫–∞–º –≤–Ω–∏–º–∞–Ω–∏—è) –∏ –æ–±—É—á–∞–µ—Ç —Ç–æ–ª—å–∫–æ —ç—Ç–∏ –º–∞—Ç—Ä–∏—Ü—ã –≤–æ –≤—Ä–µ–º—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞.\n",
        "\n",
        "–í–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —ç—Ç–∏ –º–∞—Ç—Ä–∏—Ü—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è _—Å–ª–∏–≤–∞—é—Ç—Å—è_ —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –º–æ–¥–µ–ª–∏. –ë–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ –º–æ–∂–Ω–æ –ø–æ—á–∏—Ç–∞—Ç—å –≤ [–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç—å–µ LoRA](https://arxiv.org/abs/2106.09685).\n",
        "\n",
        "<div>\n",
        "<img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png\" width=70%/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbLVDhAoZkPj"
      },
      "source": [
        "### MVP –∞–ª–≥–æ—Ä–∏—Ç–º–∞"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQwQjp2ZZkPk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import math\n",
        "from typing import Optional, List\n",
        "\n",
        "\n",
        "class LoRALayer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        r: int,\n",
        "        lora_alpha: int,\n",
        "        lora_dropout: float,\n",
        "        merge_weights: bool,\n",
        "    ):\n",
        "        self.r = r\n",
        "        self.lora_alpha = lora_alpha\n",
        "        # Optional dropout\n",
        "        if lora_dropout > 0.0:\n",
        "            self.lora_dropout = nn.Dropout(p=lora_dropout)\n",
        "        else:\n",
        "            self.lora_dropout = lambda x: x\n",
        "        # Mark the weight as unmerged\n",
        "        self.merged = False\n",
        "        self.merge_weights = merge_weights\n",
        "\n",
        "\n",
        "class Linear(nn.Linear, LoRALayer):\n",
        "    # LoRA implemented in a dense layer\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_features: int,\n",
        "        r: int = 0,\n",
        "        lora_alpha: int = 1,\n",
        "        lora_dropout: float = 0.0,\n",
        "        fan_in_fan_out: bool = False,  # Set this to True if the layer to replace stores weight like (fan_in, fan_out)\n",
        "        merge_weights: bool = True,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        nn.Linear.__init__(self, in_features, out_features, **kwargs)\n",
        "        LoRALayer.__init__(self, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout, merge_weights=merge_weights)\n",
        "\n",
        "        self.fan_in_fan_out = fan_in_fan_out\n",
        "        # Actual trainable parameters\n",
        "        if r > 0:\n",
        "            ## YOUR CODE HERE ##\n",
        "            # lora_A, lora_B, scaling...\n",
        "            # Freezing the pre-trained weight matrix\n",
        "            self.weight.requires_grad = False\n",
        "        self.reset_parameters()\n",
        "        if fan_in_fan_out:\n",
        "            self.weight.data = self.weight.data.transpose(0, 1)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.Linear.reset_parameters(self)\n",
        "        if hasattr(self, \"lora_A\"):\n",
        "            # initialize A the same way as the default for nn.Linear and B to zero\n",
        "            # this is different than what is described in the paper but should not affect performance\n",
        "            nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
        "            nn.init.zeros_(self.lora_B)\n",
        "\n",
        "    def train(self, mode: bool = True):\n",
        "        def T(w):\n",
        "            return w.transpose(0, 1) if self.fan_in_fan_out else w\n",
        "\n",
        "        nn.Linear.train(self, mode)\n",
        "        if mode:\n",
        "            if self.merge_weights and self.merged:\n",
        "                # Make sure that the weights are not merged\n",
        "                if self.r > 0:\n",
        "                    self.weight.data -= T(self.lora_B @ self.lora_A) * self.scaling\n",
        "                self.merged = False\n",
        "        else:\n",
        "            if self.merge_weights and not self.merged:\n",
        "                # Merge the weights and mark it\n",
        "                if self.r > 0:\n",
        "                    self.weight.data += T(self.lora_B @ self.lora_A) * self.scaling\n",
        "                self.merged = True\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        def T(w):\n",
        "            return w.transpose(0, 1) if self.fan_in_fan_out else w\n",
        "\n",
        "        ## YOUR CODE HERE ##\n",
        "        # W [out, in], x [B, in] -> W.T @ x\n",
        "        # Wx + B @ A @ dropout(x)...\n",
        "\n",
        "        ## YOUR CODE HERE ##\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R-r5W3ERjkz"
      },
      "outputs": [],
      "source": [
        "B = 15\n",
        "in_features, out_features = 40, 70\n",
        "\n",
        "test_tensor = torch.randn(B, in_features)\n",
        "\n",
        "lora_linear_layer = Linear(in_features, out_features, r=16, fan_in_fan_out=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM_R0XYqZkPk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxdsjAf-S1ax"
      },
      "outputs": [],
      "source": [
        "lora_linear_layer.lora_A.shape, lora_linear_layer.lora_B.shape, lora_linear_layer.fan_in_fan_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jJEsq7zSWCI"
      },
      "outputs": [],
      "source": [
        "lora_linear_layer(test_tensor).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMl4MbgJSB_D"
      },
      "outputs": [],
      "source": [
        "lora_linear_layer.training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9Cu7j_QGVbH"
      },
      "source": [
        "### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 150 —ç–∫–∑–µ–º–ø–ª—è—Ä–æ–≤ –∏–∑ —Ç—Ä–µ–π–Ω—Å–µ—Ç–∞ [SceneParse150](https://huggingface.co/datasets/scene_parse_150), —á—Ç–æ–±—ã —É–ª–æ–∂–∏—Ç—å—Å—è –≤ —Å–µ–º–∏–Ω–∞—Ä."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGJWDwtHZTwn",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"scene_parse_150\", split=\"train[:150]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpSPx8EHGeLM"
      },
      "source": [
        "### –¢—Ä–µ–π–Ω –∏ —Ç–µ—Å—Ç"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydWKIqCUZTwo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "ds = ds.train_test_split(test_size=0.1)\n",
        "train_ds = ds[\"train\"]\n",
        "test_ds = ds[\"test\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHtqAQ2WGhlR"
      },
      "source": [
        "### –õ–µ–π–±–ª—ã –∏ id\n",
        "\n",
        "–ú—ã —Å–æ–∑–¥–∞–µ–º –¥–≤–∞ —Å–ª–æ–≤–∞—Ä—è:\n",
        "\n",
        "* `label2id`: –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ –∫–ª–∞—Å—Å—ã –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã.\n",
        "* `id2label`: `label2id` –Ω–∞–æ–±–æ—Ä–æ—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hu8Y4dEIZTwq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from huggingface_hub import cached_download, hf_hub_url\n",
        "\n",
        "repo_id = \"huggingface/label-files\"\n",
        "filename = \"ade20k-id2label.json\"\n",
        "id2label = json.load(open(cached_download(hf_hub_url(repo_id, filename, repo_type=\"dataset\")), \"r\"))\n",
        "id2label = {int(k): v for k, v in id2label.items()}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "num_labels = len(id2label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8nhdt0HBsk"
      },
      "source": [
        "### –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º—ã –∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNi_TKYpZTwq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "checkpoint = \"nvidia/mit-b0\"\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint, do_reduce_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAjiYzklZTwr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ColorJitter\n",
        "\n",
        "jitter = ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn9OjpJOZkPm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGsIiwetZkPm",
        "tags": []
      },
      "outputs": [],
      "source": [
        "plt.imshow(ds[\"train\"][1][\"image\"])\n",
        "plt.show()\n",
        "plt.imshow(ds[\"train\"][1][\"annotation\"], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HaS12U0ZTwr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def handle_grayscale_image(image):\n",
        "    np_image = np.array(image)\n",
        "    if np_image.ndim == 2:\n",
        "        tiled_image = np.tile(np.expand_dims(np_image, -1), 3)\n",
        "        return Image.fromarray(tiled_image)\n",
        "    else:\n",
        "        return Image.fromarray(np_image)\n",
        "\n",
        "\n",
        "def train_transforms(example_batch):\n",
        "    images = [jitter(handle_grayscale_image(x)) for x in example_batch[\"image\"]]\n",
        "    labels = [x for x in example_batch[\"annotation\"]]\n",
        "    inputs = image_processor(images, labels)\n",
        "    return inputs\n",
        "\n",
        "\n",
        "def val_transforms(example_batch):\n",
        "    images = [handle_grayscale_image(x) for x in example_batch[\"image\"]]\n",
        "    labels = [x for x in example_batch[\"annotation\"]]\n",
        "    inputs = image_processor(images, labels)\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qyjsvup2ZTws",
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_ds.set_transform(train_transforms)\n",
        "test_ds.set_transform(val_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu8RjicxHJiO"
      },
      "source": [
        "### –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
        "\n",
        "–í–∫–ª—é—á–∏–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–∞—á–µ—Å—Ç–≤–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è. –ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–æ–¥ –æ—Ü–µ–Ω–∫–∏ —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ [ü§ó Evaluate](https://huggingface.co/docs/evaluate/index). –î–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –ø–æ–¥–æ–π–¥—ë—Ç [mean Intersection over Union (IoU)](https://huggingface.co/spaces/evaluate-metric/accuracy) (—Å–º. ü§ó Evaluate [quick tour](https://huggingface.co/docs/evaluate/a_quick_tour), —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ —Ç–æ–º, –∫–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –≤—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫—É):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMSnlebfZTwt",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"mean_iou\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    with torch.no_grad():\n",
        "        logits, labels = eval_pred\n",
        "        logits_tensor = torch.from_numpy(logits)\n",
        "        # scale the logits to the size of the label\n",
        "        logits_tensor = nn.functional.interpolate(\n",
        "            logits_tensor,\n",
        "            size=labels.shape[-2:],\n",
        "            mode=\"bilinear\",\n",
        "            align_corners=False,\n",
        "        ).argmax(dim=1)\n",
        "\n",
        "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
        "        # currently using _compute instead of compute\n",
        "        # see this issue for more info: https://github.com/huggingface/evaluate/pull/328#issuecomment-1286866576\n",
        "        metrics = metric._compute(\n",
        "            predictions=pred_labels,\n",
        "            references=labels,\n",
        "            num_labels=len(id2label),\n",
        "            ignore_index=0,\n",
        "            reduce_labels=image_processor.do_reduce_labels,\n",
        "        )\n",
        "\n",
        "        # add per category metrics as individual key-value pairs\n",
        "        per_category_accuracy = metrics.pop(\"per_category_accuracy\").tolist()\n",
        "        per_category_iou = metrics.pop(\"per_category_iou\").tolist()\n",
        "\n",
        "        metrics.update({f\"accuracy_{id2label[i]}\": v for i, v in enumerate(per_category_accuracy)})\n",
        "        metrics.update({f\"iou_{id2label[i]}\": v for i, v in enumerate(per_category_iou)})\n",
        "\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r304cnpxHxp5"
      },
      "source": [
        "### –ó–∞–≥—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å\n",
        "\n",
        "–ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏ —Ç–∞–∫ –Ω–µ –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π [SegFormer B0 variant](https://huggingface.co/nvidia/mit-b0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krvppe44a_7y",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    return f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_Wwl_ewID9I"
      },
      "source": [
        "–ú—ã –ø–µ—Ä–µ–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä–∏ `label2id` –∏ `id2label`, —á—Ç–æ–±—ã –∫–ª–∞—Å—Å `AutoModelForSemanticSegmentation` –∑–Ω–∞–ª, —á—Ç–æ –Ω–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∞—è –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å, –≤ –∫–æ—Ç–æ—Ä–æ–π –≥–æ–ª–æ–≤–∫–∞ –¥–µ–∫–æ–¥–µ—Ä–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å —É—á–µ—Ç–æ–º –Ω–∞—à–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö. –ó–∞–º–µ—Ç–∏–º, –æ–¥–Ω–∞–∫–æ, —á—Ç–æ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω—ã –∏ –±—É–¥—É—Ç –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å—Å—è –≤ —Ä–∞–º–∫–∞—Ö –æ–±—ã—á–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
        "\n",
        "–í–∏–¥–∏–º, —á—Ç–æ 100% –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ `model` –æ–±—É—á–∞–µ–º—ã–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcdLdvIlZTwt",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSemanticSegmentation, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSemanticSegmentation.from_pretrained(\n",
        "    checkpoint, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True\n",
        ")\n",
        "get_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yhyYVTCInF0"
      },
      "source": [
        "### –û–±–æ—Ä–∞—á–∏–≤–∞–µ–º `model` –≤ `PeftModel` –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å LoRA\n",
        "\n",
        "–≠—Ç–æ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –¥–≤–∞ —à–∞–≥–∞:\n",
        "\n",
        "* –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å –ø–æ–º–æ—â—å—é `LoraConfig`\n",
        "* –û–±–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–π `–º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é `get_peft_model()` —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π –≤ —à–∞–≥–µ –≤—ã—à–µ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBLcMSBCVRkk"
      },
      "outputs": [],
      "source": [
        "LoraConfig?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPg4W5eFB__n",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"lora_only\",\n",
        "    modules_to_save=[\"decode_head\"],\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(model, config)\n",
        "get_trainable_parameters(lora_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M3wYekOI95X"
      },
      "source": [
        "–î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º—Å—è, —á—Ç–æ –∑–¥–µ—Å—å –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç.\n",
        "\n",
        "–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã LoRA –Ω–∞—á–∞–ª–∞ –¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å, –Ω–∞–º –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å —Ü–µ–ª–µ–≤—ã–µ –º–æ–¥—É–ª–∏ –≤ `LoraConfig`, —á—Ç–æ–±—ã `PeftModel` –∑–Ω–∞–ª, –∫–∞–∫–∏–µ –º–æ–¥—É–ª–∏ –≤–Ω—É—Ç—Ä–∏ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ –Ω—É–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç—å –º–∞—Ç—Ä–∏—Ü–∞–º–∏ LoRA. –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ –Ω–∞—Å –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç —Ç–æ–ª—å–∫–æ –º–∞—Ç—Ä–∏—Ü—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –∏ –∑–Ω–∞—á–µ–Ω–∏–π –±–ª–æ–∫–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –ü–æ—Å–∫–æ–ª—å–∫—É –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —ç—Ç–∏–º –º–∞—Ç—Ä–∏—Ü–∞–º, ¬´–Ω–∞–∑–≤–∞–Ω—ã¬ª `query` –∏ `value` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –º—ã —É–∫–∞–∑—ã–≤–∞–µ–º –∏—Ö —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–µ `target_modules` –≤ `LoraConfig`.\n",
        "\n",
        "–ú—ã —Ç–∞–∫–∂–µ —É–∫–∞–∑—ã–≤–∞–µ–º `modules_to_save`. –ü–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –º—ã –æ–±–µ—Ä–Ω—É–ª–∏ –Ω–∞—à—É –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å `model` –≤ `PeftModel` –≤–º–µ—Å—Ç–µ —Å `config`, –º—ã –ø–æ–ª—É—á–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å, –≤ –∫–æ—Ç–æ—Ä–æ–π –æ–±—É—á–∞–µ–º—ã–º–∏ —è–≤–ª—è—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LoRA (—Ç–∞–∫ –Ω–∞–∑—ã–≤–∞–µ–º—ã–µ ¬´–º–∞—Ç—Ä–∏—Ü—ã –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è¬ª), –∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Å—Ç–∞—é—Ç—Å—è –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º–∏. –ö –Ω–∏–º –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–ª—É—á–∞–π–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞. –≠—Ç–æ–≥–æ –º—ã –Ω–µ —Ö–æ—Ç–∏–º –ø—Ä–∏ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–∞—à–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö. –ß—Ç–æ–±—ã –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å, —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ —Ç–∞–∫–∂–µ –±—É–¥—É—Ç –æ–±—É—á–µ–Ω—ã, –º—ã —É–∫–∞–∑—ã–≤–∞–µ–º `modules_to_save`. –≠—Ç–æ —Ç–∞–∫–∂–µ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ —ç—Ç–∏ –º–æ–¥—É–ª–∏ –±—É–¥—É—Ç —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤–º–µ—Å—Ç–µ —Å –æ–±—É—á–∞–µ–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ LoRA –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ç–∞–∫–∏—Ö —É—Ç–∏–ª–∏—Ç, –∫–∞–∫ `save_pretrained()` –∏ `push_to_hub()`.  \n",
        "\n",
        "–ß—Ç–æ –∫–∞—Å–∞–µ—Ç—Å—è –¥—Ä—É–≥–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:\n",
        "\n",
        "* `r`: –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–∞—Ç—Ä–∏—Ü–∞–º–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è LoRA.\n",
        "* `alpha`: –ú–∞—Å—à—Ç–∞–±–∏—Ä—É—é—â–∏–π —Ñ–∞–∫—Ç–æ—Ä.\n",
        "* `bias`: –£–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—É—á–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã `bias`. `lora_only` –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –±—É–¥—É—Ç –æ–±—É—á–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã `bias` LoRA.\n",
        "\n",
        "`r` –∏ `alpha` –≤–º–µ—Å—Ç–µ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É—é—Ç –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–Ω–µ—á–Ω—ã—Ö –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ LoRA, –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—è –Ω–∞–º –≥–∏–±–∫–æ—Å—Ç—å –≤ –ø–æ–∏—Å–∫–µ –∫–æ–º–ø—Ä–æ–º–∏—Å—Å–∞ –º–µ–∂–¥—É –∫–æ–Ω–µ—á–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é –≤—ã—á–∏—Å–ª–µ–Ω–∏–π."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTF68xfjJEci"
      },
      "source": [
        "–ú—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º—ã –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –æ–±—É—á–∞–µ–º. –ü–æ—Å–∫–æ–ª—å–∫—É –º—ã –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω—ã –≤ **parameter-efficient fine-tuning**, –º—ã –¥–æ–ª–∂–Ω—ã –æ–∂–∏–¥–∞—Ç—å, —á—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ `lora_model` –±—É–¥–µ—Ç –º–µ–Ω—å—à–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –∏—Å—Ö–æ–¥–Ω–æ–π `model`, —á—Ç–æ –∏ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç.\n",
        "\n",
        "–ß—Ç–æ–±—ã –Ω–µ –æ—à–∏–±–∏—Ç—å—Å—è, –¥–∞–≤–∞–π—Ç–µ —Ç–∞–∫–∂–µ –≤—Ä—É—á–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∏–º –º–æ–¥—É–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ø–æ–¥–¥–∞—é—Ç—Å—è –æ–±—É—á–µ–Ω–∏—é –≤ `lora_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjURTASCU9W6"
      },
      "outputs": [],
      "source": [
        "all_params = []\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    all_params.append((name, param.shape))\n",
        "print(*grad_params, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUe1Gzvd1PEP",
        "tags": []
      },
      "outputs": [],
      "source": [
        "grad_params = []\n",
        "\n",
        "for name, param in lora_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        grad_params.append((name, param.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCKZ0tVEZkPo",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(*grad_params, sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3EnOAbHZkPo"
      },
      "source": [
        "–ú—ã –º–æ–∂–µ–º –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å, —á—Ç–æ —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å LoRA, –¥–æ–±–∞–≤–ª—è–µ–º—ã–µ –∫ –±–ª–æ–∫–∞–º –≤–Ω–∏–º–∞–Ω–∏—è, –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã `decode_head` —Ç–µ–ø–µ—Ä—å –æ–±—É—á–∞–µ–º—ã."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX75AyI7JYVC"
      },
      "source": [
        "### –¢—Ä–µ–Ω–∏—Ä—É–µ–º!\n",
        "\n",
        "–≠—Ç–æ –¥–≤—É—Ö—ç—Ç–∞–ø–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å:\n",
        "\n",
        "1. –û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è –≤ [TrainingArguments](https://huggingface.co/docs/transformers/v4.26.0/en/main_classes/trainer#transformers.TrainingArguments). –í–∞–∂–Ω–æ –Ω–µ —É–¥–∞–ª—è—Ç—å –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –ø—Ä–∏–≤–µ–¥–µ—Ç –∫ –∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏—é —Å—Ç–æ–ª–±—Ü–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ë–µ–∑ —Å—Ç–æ–ª–±—Ü–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤—ã –Ω–µ —Å–º–æ–∂–µ—Ç–µ —Å–æ–∑–¥–∞—Ç—å `pixel_values`. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `remove_unused_columns=False`, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å —Ç–∞–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ! –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –¥—Ä—É–≥–æ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä - output_dir, –∫–æ—Ç–æ—Ä—ã–π —É–∫–∞–∑—ã–≤–∞–µ—Ç, –∫—É–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–æ–¥–µ–ª—å. –í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ `Trainer` –±—É–¥–µ—Ç –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É IoU –∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—É—é —Ç–æ—á–∫—É –æ–±—É—á–µ–Ω–∏—è.\n",
        "2. –ü–µ—Ä–µ–¥–∞–π—Ç–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –æ–±—É—á–µ–Ω–∏—è –≤ [Trainer](https://huggingface.co/docs/transformers/v4.26.0/en/main_classes/trainer#transformers.Trainer) –≤–º–µ—Å—Ç–µ —Å –º–æ–¥–µ–ª—å—é, –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º, –∫–æ–ª–ª–∞—Ç–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö –∏ —Ñ—É–Ω–∫—Ü–∏–µ–π `compute_metrics`.\n",
        "3. –í—ã–∑–æ–≤–∏—Ç–µ `train()` –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "\n",
        "**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏—è —Å —Ä–∞–±–æ—á–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ PEFT –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏. –ú—ã –Ω–µ –ø—Ä–æ–≤–æ–¥–∏–ª–∏ –æ–±—à–∏—Ä–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6HVcNkDZTwu",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "\n",
        "model_name = checkpoint.split(\"/\")[-1]\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"{model_name}-scene-parse-{len(ds['train'])}-lora\",\n",
        "    learning_rate=5e-4,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    dataloader_num_workers=8,\n",
        "    per_device_eval_batch_size=4,\n",
        "    save_total_limit=3,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    warmup_ratio=0.05,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=5,\n",
        "    bf16=True,\n",
        "    remove_unused_columns=False,\n",
        "    push_to_hub=True,\n",
        "    label_names=[\"labels\"],\n",
        "    report_to=\"wandb\",\n",
        "    seed=1337,\n",
        "    run_name=\"b0-lora-baseline\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGwdtxLsZkPy",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy0bnUT1ZkPy",
        "tags": []
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFrNo1hSXT5a"
      },
      "outputs": [],
      "source": [
        "wandb.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0gNRLe5XK0Y"
      },
      "outputs": [],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dacaBLE6KLdu"
      },
      "source": [
        "### –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å\n",
        "\n",
        "–ó–¥–µ—Å—å –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ `save_pretrained()` –∏–∑ `lora_model` –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è *LoRA-only –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤*. –û–¥–Ω–∞–∫–æ –≤—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ `push_to_hub()` –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —ç—Ç–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –≤ Hugging Face Hub (–∫–∞–∫ –ø–æ–∫–∞–∑–∞–Ω–æ [–∑–¥–µ—Å—å](https://colab.research.google.com/github/huggingface/peft/blob/main/examples/image_classification/image_classification_peft_lora.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvkLkrQo-6l6"
      },
      "outputs": [],
      "source": [
        "model_id = \"segformer-scene-parse-150-lora\"\n",
        "lora_model.save_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur8n41kBK4uj"
      },
      "source": [
        "–ú—ã –≤–∏–¥–∏–º, —á—Ç–æ —Ä–∞–∑–º–µ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è LoRA —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤—Å–µ–≥–æ **2,2 –ú–ë**! –≠—Ç–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∞–µ—Ç –ø–µ—Ä–µ–Ω–æ—Å–∏–º–æ—Å—Ç—å –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grzLeOT-__ht"
      },
      "outputs": [],
      "source": [
        "!ls -lh {model_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFYC6Z3FLB5F"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –Ω–∞—à—É `inference_model` –∏ –∑–∞–ø—É—Å—Ç–∏–º –µ—ë."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7zeMQTaACur"
      },
      "outputs": [],
      "source": [
        "from peft import PeftConfig, PeftModel\n",
        "\n",
        "config = PeftConfig.from_pretrained(model_id)\n",
        "model = AutoModelForSemanticSegmentation.from_pretrained(\n",
        "    checkpoint, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Load the Lora model\n",
        "inference_model = PeftModel.from_pretrained(model, model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMFea_fEXrV3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L1R0LDWLImd"
      },
      "source": [
        "–î–æ—Å—Ç–∞—ë–º –∫–∞—Ä—Ç–∏–Ω–∫—É:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwjRvZOmA7Hh"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/semantic-seg-image.png\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdK_bGhsLKKE"
      },
      "source": [
        "–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–º\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0z-3R-PBKc9"
      },
      "outputs": [],
      "source": [
        "# prepare image for the model\n",
        "encoding = image_processor(image.convert(\"RGB\"), return_tensors=\"pt\")\n",
        "print(encoding.pixel_values.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJRijta4LLu9"
      },
      "source": [
        "–ü—Ä–æ–≥–æ–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1p-QDoiBP56"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = inference_model(pixel_values=encoding.pixel_values)\n",
        "    logits = outputs.logits\n",
        "\n",
        "upsampled_logits = nn.functional.interpolate(\n",
        "    logits,\n",
        "    size=image.size[::-1],\n",
        "    mode=\"bilinear\",\n",
        "    align_corners=False,\n",
        ")\n",
        "\n",
        "pred_seg = upsampled_logits.argmax(dim=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmYIcfL4LNtj"
      },
      "source": [
        "–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.\n",
        "\n",
        "–ù–∞–º –Ω—É–∂–Ω–∞ —Ü–≤–µ—Ç–æ–≤–∞—è –ø–∞–ª–∏—Ç—Ä–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤. –ó–¥–µ—Å—å –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º [–æ–¥–Ω—É –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º TensorFlow Model Garden](https://github.com/tensorflow/models/blob/3f1ca33afe3c1631b733ea7e40c294273b9e406d/research/deeplab/utils/get_dataset_colormap.py#L51)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy5c6vmzBqzC"
      },
      "outputs": [],
      "source": [
        "def ade_palette():\n",
        "    \"\"\"Creates a label colormap used in ADE20K segmentation benchmark.\n",
        "    Returns:\n",
        "    A colormap for visualizing segmentation results.\n",
        "    \"\"\"\n",
        "    return np.asarray(\n",
        "        [\n",
        "            [0, 0, 0],\n",
        "            [120, 120, 120],\n",
        "            [180, 120, 120],\n",
        "            [6, 230, 230],\n",
        "            [80, 50, 50],\n",
        "            [4, 200, 3],\n",
        "            [120, 120, 80],\n",
        "            [140, 140, 140],\n",
        "            [204, 5, 255],\n",
        "            [230, 230, 230],\n",
        "            [4, 250, 7],\n",
        "            [224, 5, 255],\n",
        "            [235, 255, 7],\n",
        "            [150, 5, 61],\n",
        "            [120, 120, 70],\n",
        "            [8, 255, 51],\n",
        "            [255, 6, 82],\n",
        "            [143, 255, 140],\n",
        "            [204, 255, 4],\n",
        "            [255, 51, 7],\n",
        "            [204, 70, 3],\n",
        "            [0, 102, 200],\n",
        "            [61, 230, 250],\n",
        "            [255, 6, 51],\n",
        "            [11, 102, 255],\n",
        "            [255, 7, 71],\n",
        "            [255, 9, 224],\n",
        "            [9, 7, 230],\n",
        "            [220, 220, 220],\n",
        "            [255, 9, 92],\n",
        "            [112, 9, 255],\n",
        "            [8, 255, 214],\n",
        "            [7, 255, 224],\n",
        "            [255, 184, 6],\n",
        "            [10, 255, 71],\n",
        "            [255, 41, 10],\n",
        "            [7, 255, 255],\n",
        "            [224, 255, 8],\n",
        "            [102, 8, 255],\n",
        "            [255, 61, 6],\n",
        "            [255, 194, 7],\n",
        "            [255, 122, 8],\n",
        "            [0, 255, 20],\n",
        "            [255, 8, 41],\n",
        "            [255, 5, 153],\n",
        "            [6, 51, 255],\n",
        "            [235, 12, 255],\n",
        "            [160, 150, 20],\n",
        "            [0, 163, 255],\n",
        "            [140, 140, 140],\n",
        "            [250, 10, 15],\n",
        "            [20, 255, 0],\n",
        "            [31, 255, 0],\n",
        "            [255, 31, 0],\n",
        "            [255, 224, 0],\n",
        "            [153, 255, 0],\n",
        "            [0, 0, 255],\n",
        "            [255, 71, 0],\n",
        "            [0, 235, 255],\n",
        "            [0, 173, 255],\n",
        "            [31, 0, 255],\n",
        "            [11, 200, 200],\n",
        "            [255, 82, 0],\n",
        "            [0, 255, 245],\n",
        "            [0, 61, 255],\n",
        "            [0, 255, 112],\n",
        "            [0, 255, 133],\n",
        "            [255, 0, 0],\n",
        "            [255, 163, 0],\n",
        "            [255, 102, 0],\n",
        "            [194, 255, 0],\n",
        "            [0, 143, 255],\n",
        "            [51, 255, 0],\n",
        "            [0, 82, 255],\n",
        "            [0, 255, 41],\n",
        "            [0, 255, 173],\n",
        "            [10, 0, 255],\n",
        "            [173, 255, 0],\n",
        "            [0, 255, 153],\n",
        "            [255, 92, 0],\n",
        "            [255, 0, 255],\n",
        "            [255, 0, 245],\n",
        "            [255, 0, 102],\n",
        "            [255, 173, 0],\n",
        "            [255, 0, 20],\n",
        "            [255, 184, 184],\n",
        "            [0, 31, 255],\n",
        "            [0, 255, 61],\n",
        "            [0, 71, 255],\n",
        "            [255, 0, 204],\n",
        "            [0, 255, 194],\n",
        "            [0, 255, 82],\n",
        "            [0, 10, 255],\n",
        "            [0, 112, 255],\n",
        "            [51, 0, 255],\n",
        "            [0, 194, 255],\n",
        "            [0, 122, 255],\n",
        "            [0, 255, 163],\n",
        "            [255, 153, 0],\n",
        "            [0, 255, 10],\n",
        "            [255, 112, 0],\n",
        "            [143, 255, 0],\n",
        "            [82, 0, 255],\n",
        "            [163, 255, 0],\n",
        "            [255, 235, 0],\n",
        "            [8, 184, 170],\n",
        "            [133, 0, 255],\n",
        "            [0, 255, 92],\n",
        "            [184, 0, 255],\n",
        "            [255, 0, 31],\n",
        "            [0, 184, 255],\n",
        "            [0, 214, 255],\n",
        "            [255, 0, 112],\n",
        "            [92, 255, 0],\n",
        "            [0, 224, 255],\n",
        "            [112, 224, 255],\n",
        "            [70, 184, 160],\n",
        "            [163, 0, 255],\n",
        "            [153, 0, 255],\n",
        "            [71, 255, 0],\n",
        "            [255, 0, 163],\n",
        "            [255, 204, 0],\n",
        "            [255, 0, 143],\n",
        "            [0, 255, 235],\n",
        "            [133, 255, 0],\n",
        "            [255, 0, 235],\n",
        "            [245, 0, 255],\n",
        "            [255, 0, 122],\n",
        "            [255, 245, 0],\n",
        "            [10, 190, 212],\n",
        "            [214, 255, 0],\n",
        "            [0, 204, 255],\n",
        "            [20, 0, 255],\n",
        "            [255, 255, 0],\n",
        "            [0, 153, 255],\n",
        "            [0, 41, 255],\n",
        "            [0, 255, 204],\n",
        "            [41, 0, 255],\n",
        "            [41, 255, 0],\n",
        "            [173, 0, 255],\n",
        "            [0, 245, 255],\n",
        "            [71, 0, 255],\n",
        "            [122, 0, 255],\n",
        "            [0, 255, 184],\n",
        "            [0, 92, 255],\n",
        "            [184, 255, 0],\n",
        "            [0, 133, 255],\n",
        "            [255, 214, 0],\n",
        "            [25, 194, 194],\n",
        "            [102, 255, 0],\n",
        "            [92, 0, 255],\n",
        "        ]\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVbjFULuZkP2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "color_seg = np.zeros((pred_seg.shape[0], pred_seg.shape[1], 3), dtype=np.uint8)\n",
        "palette = np.array(ade_palette())\n",
        "\n",
        "for label, color in enumerate(palette):\n",
        "    color_seg[pred_seg == label, :] = color\n",
        "color_seg = color_seg[..., ::-1]  # convert to BGR\n",
        "color_idx = np.unique(pred_seg)\n",
        "\n",
        "labels = [id2label[i] for i in color_idx]\n",
        "\n",
        "img = np.array(image) * 0.5 + color_seg * 0.5  # plot the image with the segmentation map\n",
        "img = img.astype(np.uint8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KJFvgENBih0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(img)\n",
        "plt.barh(\n",
        "    y=np.arange(len(color_idx)) * 10 + 10,\n",
        "    height=np.ones(len(color_idx)) * 10,\n",
        "    width=10,\n",
        "    tick_label=labels,\n",
        "    align=\"center\",\n",
        "    color=palette[color_idx] / 255.0,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1aGuHYFLP7i"
      },
      "source": [
        "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–∂–∏–¥–∞–Ω–∏—è–º, –∏, –∫–∞–∫ —É–∂–µ –≥–æ–≤–æ—Ä–∏–ª–æ—Å—å –≤—ã—à–µ, —ç—Ç–æ—Ç –ø—Ä–∏–º–µ—Ä –Ω–µ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–æ–π —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏. –û–Ω —Å–æ–∑–¥–∞–Ω –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –æ–∑–Ω–∞–∫–æ–º–∏—Ç—å –≤–∞—Å —Å–æ –≤—Å–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º —Ä–∞–±–æ—Ç—ã.\n",
        "\n",
        "–° –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, –µ—Å–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—É—é —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –Ω–∞ —Ç–æ–π –∂–µ —É—Å—Ç–∞–Ω–æ–≤–∫–µ (—Ç–æ—Ç –∂–µ –≤–∞—Ä–∏–∞–Ω—Ç –º–æ–¥–µ–ª–∏, —Ç–æ—Ç –∂–µ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, —Ç–æ—Ç –∂–µ –≥—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è –∏ —Ç. –¥.), —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –±—É–¥—É—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è. –≠—Ç–æ –≤–∞–∂–Ω—ã–π –∞—Å–ø–µ–∫—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ - –±—ã—Ç—å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–æ–ª–Ω–æ–π —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, –Ω–æ —Å —á–∞—Å—Ç—å—é –≤—Å–µ—Ö –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
        "\n",
        "–í–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—â–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:\n",
        "\n",
        "* –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö.\n",
        "* –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ SegFormer (–æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ —É–∑–Ω–∞—Ç—å [–∑–¥–µ—Å—å](https://huggingface.co/models?search=segformer)).\n",
        "* –¢—é–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤, –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –≤ `LoraConfig`.\n",
        "* –¢—é–Ω–∏—Ç—å –æ–±—ã—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è.\n",
        "* LoRA –º–æ–∂–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑ —Ä–∞–∑–ª–æ–∂–µ–Ω–∏–π –∏—Å—Ö–æ–¥–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, SVD –≤ [PiSSA](https://arxiv.org/pdf/2404.02948)\n",
        "\n",
        "<div>\n",
        "<img src=\"https://pbs.twimg.com/media/GKrHjNlaUAIeKNp?format=jpg&name=medium\" width=70%/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxkX-1vSZkP2",
        "tags": []
      },
      "source": [
        "## 2. Distillation: (Hinton KD, Zagoruyko AT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84QKUJDnYG0G"
      },
      "outputs": [],
      "source": [
        "! pip install torchdistill -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y39ysk-qb0u7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchdistill.core.forward_hook import ForwardHookManager\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "args = {}\n",
        "kwargs = {}\n",
        "args[\"batch_size\"] = 1000\n",
        "args[\"test_batch_size\"] = 1000\n",
        "args[\"epochs\"] = 5  # The number of Epochs is the number of times you go through the full dataset.\n",
        "args[\"lr\"] = 0.1  # Learning rate is how fast it will decend.\n",
        "args[\n",
        "    \"momentum\"\n",
        "] = 0.5  # SGD momentum (default: 0.5) Momentum is a moving average of our gradients (helps to keep direction).\n",
        "\n",
        "args[\"seed\"] = 1  # random seed\n",
        "args[\"log_interval\"] = 60\n",
        "args[\"cuda\"] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4mNFQFSMObl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# fix random seeds\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    numpy.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbJbprO-dMNr",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
        "    ),\n",
        "    batch_size=args[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    worker_init_fn=seed_worker,\n",
        "    generator=g,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../data\",\n",
        "        train=False,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]),\n",
        "    ),\n",
        "    batch_size=args[\"batch_size\"],\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-Ug9UEHEwm9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train(model, epoch, optimizer, args=args):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # This will zero out the gradients for this batch.\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        # dloss/dx for every Variable\n",
        "        loss.backward()\n",
        "        # to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        # Print out the loss periodically.\n",
        "        if batch_idx % args[\"log_interval\"] == 0:\n",
        "            print(\n",
        "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "                    epoch,\n",
        "                    batch_idx * len(data),\n",
        "                    len(train_loader.dataset),\n",
        "                    100.0 * batch_idx / len(train_loader),\n",
        "                    loss.item(),\n",
        "                )\n",
        "            )\n",
        "\n",
        "\n",
        "def test(model, args=args):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target).item()  # sum up batch loss\n",
        "            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(\n",
        "        \"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "            test_loss, correct, len(test_loader.dataset), 100.0 * correct / len(test_loader.dataset)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    return 100.0 * correct / len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq_HSrCY9qi8"
      },
      "source": [
        "### –¢—Ä–µ–Ω–∏—Ä—É–µ–º Teacher-–∞ –Ω–∞ MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHk0XHfpFMfp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class TeacherNetClass(nn.Module):\n",
        "    # This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super(TeacherNetClass, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3)\n",
        "        self.conv2_drop = nn.Dropout2d()  # Dropout\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(800, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        # Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        # Fully Connected Layer/Activation\n",
        "        x = F.relu(self.fc1(self.flatten(x)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        # Softmax gets probabilities.\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqXD2v9HZkP2",
        "tags": []
      },
      "outputs": [],
      "source": [
        "teacher = TeacherNetClass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9Sm0RV4Gt6V",
        "tags": []
      },
      "outputs": [],
      "source": [
        "teacher = TeacherNetClass()\n",
        "teacher.to(device)\n",
        "\n",
        "optimizer = optim.SGD(teacher.parameters(), lr=args[\"lr\"], momentum=args[\"momentum\"])\n",
        "\n",
        "for epoch in range(args[\"epochs\"]):\n",
        "    train(teacher, epoch, optimizer)\n",
        "    test(teacher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmjDRlJ1KENQ"
      },
      "source": [
        "### –¢—Ä–µ–Ω–∏—Ä—É–µ–º Studenta-–∞ –Ω–∞ MNIST –±–µ–∑ –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–∏\n",
        "\n",
        "–ú—ã –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —É—á–µ–Ω–∏–∫–∞ —Ç–∞–∫ –∂–µ, –∫–∞–∫ –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —É—á–∏—Ç–µ–ª—è, –Ω–æ —Å –º–µ–Ω—å—à–µ–π —à–∏—Ä–∏–Ω–æ–π –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª–æ—è—Ö.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPhZOuOoKFdt",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class StudentNetClass(nn.Module):\n",
        "    # This defines the structure of the NN.\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3)\n",
        "        self.conv2_drop = nn.Dropout2d()  # Dropout\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(400, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolutional Layer/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        # Convolutional Layer/Dropout/Pooling Layer/Activation\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        # Fully Connected Layer/Activation\n",
        "        x = F.relu(self.fc1(self.flatten(x)))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # Fully Connected Layer/Activation\n",
        "        x = self.fc2(x)\n",
        "        # Softmax gets probabilities.\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEKRsODpKH7a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "student = StudentNetClass()\n",
        "student.to(device)\n",
        "acc_list_wo_kd = []\n",
        "\n",
        "optimizer = optim.SGD(student.parameters(), lr=args[\"lr\"], momentum=args[\"momentum\"])\n",
        "\n",
        "for epoch in range(args[\"epochs\"]):\n",
        "    train(student, epoch, optimizer)\n",
        "    acc_list_wo_kd.append(test(student))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGyTgmupBwuA"
      },
      "source": [
        "### –¢—Ä–µ–Ω–∏—Ä—É–µ–º Studenta-–∞ –Ω–∞ MNIST —Å –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–µ–π –ø–æ –•–∏–Ω—Ç–æ–Ω—É\n",
        "\n",
        "<div>\n",
        "<img src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/11/knowledge-distillation-general-framework.png\" width=90%/>\n",
        "</div>\n",
        "\n",
        "$$L=(1-\\alpha) L_{c e}\\left(z_{s}, y\\right)+\\alpha L_{c e}\\left(z_{s}, z_{t}\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXcvo0weBqSa",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class KDLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Distilling the Knowledge in a Neural Network\n",
        "    https://arxiv.org/abs/1503.02531\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T=1, alpha=0.1):\n",
        "        super().__init__()\n",
        "        self.T = T\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, student_pred, teacher_pred, y):\n",
        "        \"\"\"\n",
        "        Loss function for student network: Loss = alpha * (distillation loss with soft-target) + (1 - alpha) * (cross-entropy loss with true label)\n",
        "        Return: loss\n",
        "        \"\"\"\n",
        "        hard_loss =  F.cross_entropy(student_pred, y)\n",
        "        if self.alpha > 0:\n",
        "            ### YOUR CODE HERE ###\n",
        "            # soft_loss = ...\n",
        "            loss = self.alpha * soft_loss + (1 - self.alpha) * hard_loss\n",
        "        else:\n",
        "            loss = hard_loss\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tA0udaaKCDBl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train_kd(\n",
        "    teacher,\n",
        "    student,\n",
        "    epoch,\n",
        "    optimizer,\n",
        "    kd_loss,\n",
        "    alpha=0.1,\n",
        "    args=args,\n",
        "):\n",
        "    teacher.to(device)\n",
        "    teacher.eval()\n",
        "    student.train()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        # This will zero out the gradients for this batch.\n",
        "        optimizer.zero_grad()\n",
        "        output = student(data)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_t = teacher(data)\n",
        "\n",
        "        # Calculate KD Loss\n",
        "        loss = kd_loss(output, output_t, target)\n",
        "        # dloss/dx for every Variable\n",
        "        loss.backward()\n",
        "        # to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        # Print out the loss periodically.\n",
        "        if batch_idx % args[\"log_interval\"] == 0:\n",
        "            print(\n",
        "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "                    epoch,\n",
        "                    batch_idx * len(data),\n",
        "                    len(train_loader.dataset),\n",
        "                    100.0 * batch_idx / len(train_loader),\n",
        "                    loss.item(),\n",
        "                )\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kFEzvJqCTBC",
        "tags": []
      },
      "outputs": [],
      "source": [
        "alphas = [0, 0.02, 0.07, 0.2, 0.4, 1.0]\n",
        "\n",
        "exp_dict = {}\n",
        "\n",
        "for alpha in alphas:\n",
        "    print(f\"__________(alpha = {alpha})__________\")\n",
        "    acc_list = []\n",
        "    student_hint = StudentNetClass()\n",
        "    student_hint.to(device)\n",
        "\n",
        "    # Create forward hooks for outputs of conv1 and conv2 for teacher and student\n",
        "    kd_loss = KDLoss(T=5, alpha=alpha)\n",
        "\n",
        "    optimizer = optim.SGD(student_hint.parameters(), lr=args[\"lr\"], momentum=args[\"momentum\"])\n",
        "\n",
        "    for epoch in range(args[\"epochs\"]):\n",
        "        train_kd(teacher, student_hint, epoch, optimizer, kd_loss)\n",
        "        acc_list.append(test(student_hint))\n",
        "\n",
        "    exp_dict[alpha] = acc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCvG6WsDaKam",
        "tags": []
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for alpha, acc_list in exp_dict.items():\n",
        "    plt.plot(acc_list, label=f\"alpha = {alpha}\", marker=\"o\")\n",
        "\n",
        "plt.legend()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAWsE2aaPd7s",
        "tags": []
      },
      "source": [
        "### –¢—Ä–µ–Ω–∏—Ä—É–µ–º Studenta-–∞ –Ω–∞ MNIST —Å –¥–∏—Å—Ç–∏–ª–ª—è—Ü–∏–µ–π –ø–æ –ó–∞–≥–æ—Ä—É–π–∫–æ (Attention Transfer)\n",
        "\n",
        "\n",
        "<div>\n",
        "<img src=\"https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/20e210bb6b1d3e637e2b2674aeead3fad8c2c70e/2-Figure1-1.png\" width=70%/>\n",
        "</div>\n",
        "\n",
        "$$L=(1-\\alpha) L_{c e}\\left(z_{s}, y\\right)+\\alpha L_{A T}\\left(h_{s}, h_{t}\\right)$$\n",
        "\n",
        "$$L_{A T}=L\\left(\\mathbf{W}_{S}, x\\right)+\\frac{\\beta}{2} \\sum_{j \\in I}\\left\\|\\frac{Q_{S}^{j}}{\\left\\|Q_{S}^{j}\\right\\|_{2}}-\\frac{Q_{T}^{j}}{\\left\\|Q_{T}^{j}\\right\\|_{2}}\\right\\|_{p}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z858oeVfOUgT",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class AT(nn.Module):\n",
        "    \"\"\"\n",
        "    Paying More Attention to Attention: Improving the Performance of Convolutional\n",
        "    Neural Networks wia Attention Transfer\n",
        "    https://arxiv.org/pdf/1612.03928.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p=2):\n",
        "        super(AT, self).__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, fm_s, fm_t):\n",
        "        loss = torch.norm(self.attention_map(fm_s) - self.attention_map(fm_t), self.p)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def attention_map(self, fm):\n",
        "        ### YOUR CODE HERE ###\n",
        "        # am = ...\n",
        "        return am"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz7-s87QPsbi",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def train_at(\n",
        "    teacher,\n",
        "    student,\n",
        "    epoch,\n",
        "    optimizer,\n",
        "    at_loss,\n",
        "    forward_hook_manager_teacher,\n",
        "    forward_hook_manager_student,\n",
        "    alpha=0.1,\n",
        "    args=args,\n",
        "):\n",
        "    device = \"cuda\" if args[\"cuda\"] else \"cpu\"\n",
        "    teacher.to(device)\n",
        "    teacher.eval()\n",
        "    student.train()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if args[\"cuda\"]:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "        # This will zero out the gradients for this batch.\n",
        "        optimizer.zero_grad()\n",
        "        output = student(data)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_t = teacher(data)\n",
        "\n",
        "        # Calculate the loss The negative log likelihood loss. It is useful to train a classification problem with C classes.\n",
        "        loss_label = F.cross_entropy(output, target)\n",
        "\n",
        "        # Calculate Attention loss\n",
        "        teacher_io_dict = forward_hook_manager_teacher.pop_io_dict()\n",
        "        student_io_dict = forward_hook_manager_student.pop_io_dict()\n",
        "        loss_at = at_loss(student_io_dict[\"conv1\"][\"output\"], teacher_io_dict[\"conv1\"][\"output\"]) + at_loss(\n",
        "            student_io_dict[\"conv2\"][\"output\"], teacher_io_dict[\"conv2\"][\"output\"]\n",
        "        )\n",
        "\n",
        "        loss = (1 - alpha) * loss_label + alpha * loss_at\n",
        "        # dloss/dx for every Variable\n",
        "        loss.backward()\n",
        "        # to do a one-step update on our parameter.\n",
        "        optimizer.step()\n",
        "        # Print out the loss periodically.\n",
        "        if batch_idx % args[\"log_interval\"] == 0:\n",
        "            print(\n",
        "                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "                    epoch,\n",
        "                    batch_idx * len(data),\n",
        "                    len(train_loader.dataset),\n",
        "                    100.0 * batch_idx / len(train_loader),\n",
        "                    loss.item(),\n",
        "                )\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYK5OESOP-cp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "alphas = [0, 0.05, 0.07, 0.1, 0.2, 0.4, 0.5, 1.0]\n",
        "\n",
        "exp_dict = {}\n",
        "\n",
        "for alpha in alphas:\n",
        "    print(f\"__________(alpha = {alpha})__________\")\n",
        "    acc_list = []\n",
        "    forward_hook_manager_teacher = ForwardHookManager(device)\n",
        "    forward_hook_manager_student = ForwardHookManager(device)\n",
        "\n",
        "    student_at = StudentNetClass()\n",
        "    student_at.to(device)\n",
        "\n",
        "    # Create forward hooks for outputs of conv1 and conv2 for teacher and student\n",
        "\n",
        "    forward_hook_manager_teacher.add_hook(teacher, \"conv1\", requires_input=False, requires_output=True)\n",
        "    forward_hook_manager_student.add_hook(student_at, \"conv1\", requires_input=False, requires_output=True)\n",
        "\n",
        "    forward_hook_manager_teacher.add_hook(teacher, \"conv2\", requires_input=False, requires_output=True)\n",
        "    forward_hook_manager_student.add_hook(student_at, \"conv2\", requires_input=False, requires_output=True)\n",
        "\n",
        "    p = 2\n",
        "    at_loss = AT(p)\n",
        "\n",
        "    optimizer = optim.SGD(student_at.parameters(), lr=args[\"lr\"], momentum=args[\"momentum\"])\n",
        "\n",
        "    for epoch in range(args[\"epochs\"]):\n",
        "        train_at(\n",
        "            teacher,\n",
        "            student_at,\n",
        "            epoch,\n",
        "            optimizer,\n",
        "            at_loss,\n",
        "            forward_hook_manager_teacher,\n",
        "            forward_hook_manager_student,\n",
        "            alpha,\n",
        "        )\n",
        "        acc_list.append(test(student_at))\n",
        "\n",
        "    exp_dict[alpha] = acc_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zGVFxcMQJ5l",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# do not forget to close the door\n",
        "forward_hook_manager_teacher.clear()\n",
        "forward_hook_manager_student.clear()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g08KB_McJhB",
        "tags": []
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for alpha, acc_list in exp_dict.items():\n",
        "    plt.plot(acc_list, label=f\"alpha = {alpha}\", marker=\"o\")\n",
        "\n",
        "plt.legend()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHNNm1kZa9T6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for alpha, acc_list in list(exp_dict.items()):\n",
        "    if alpha != 1.0:\n",
        "        plt.plot(acc_list, label=f\"alpha = {alpha}\", marker=\"o\")\n",
        "\n",
        "plt.legend()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO9YUprMZkP4",
        "tags": []
      },
      "source": [
        "## 3. Quantization: AWQ, AQLM, bitsandbytes\n",
        "\n",
        "- [AWQ](https://huggingface.co/docs/transformers/main/en/quantization/awq): –ø—Ä–∏–º–µ—Ä –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ –±–µ–∑ –¥–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ (–±—ã—Å—Ç—Ä–æ, –Ω–æ —Å —Ö—É–¥—à–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º)\n",
        "- [AQLM](https://huggingface.co/docs/transformers/main/en/quantization/aqlm), [—Ä–µ–ø–æ](https://github.com/Vahe1994/AQLM) –∞–≤—Ç–æ—Ä–æ–≤: –ø—Ä–∏–º–µ—Ä –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ —Å –¥–æ—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–æ–π –º–∞–ª–æ–±–∏—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ (—Ç—Ä–µ–±—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–µ, –ø—Ä–æ—Å–∞–¥–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞)\n",
        "\n",
        "–û–±–∞ –º–µ—Ç–æ–¥–∞ –µ—Å—Ç—å –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ [bitsandbytes](https://huggingface.co/docs/bitsandbytes/main/en/index), –ø–æ–¥—Ä–æ–±–Ω—ã–π [–≥–∞–π–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](https://huggingface.co/docs/transformers/en/quantization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28ymuS6xiDDp"
      },
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig, AwqConfig, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "DEVICE = \"cuda:0\"\n",
        "\n",
        "quantization_config_bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "# quantization_config_awq = AwqConfig(\n",
        "#     bits=4,\n",
        "#     fuse_max_seq_len=4096,\n",
        "#     modules_to_fuse={\n",
        "#         \"attention\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "#         \"mlp\": [\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "#         \"layernorm\": [\"input_layernorm\", \"post_attention_layernorm\", \"norm\"],\n",
        "#         \"use_alibi\": False,\n",
        "#         \"num_attention_heads\": 32,\n",
        "#         \"num_key_value_heads\": 8,\n",
        "#         \"hidden_size\": 4096,\n",
        "#     }\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    quantization_config=quantization_config_bnb,\n",
        ").to(DEVICE)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python [conda env:kurkin-kurkin_312_torch]",
      "language": "python",
      "name": "conda-env-kurkin-kurkin_312_torch-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
