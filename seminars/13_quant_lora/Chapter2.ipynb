{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Глава 2: Загрузка квантованной модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Содержание главы\n",
    "\n",
    " В этой главе мы:\n",
    "\n",
    "\n",
    "\n",
    " *   Поймем, как работает квантование.\n",
    "\n",
    " *   Изучим преимущества и недостатки использования различных типов данных (FP16, BF16, FP32).\n",
    "\n",
    " *   Познакомимся с концепцией вычислений со смешанной точностью.\n",
    "\n",
    " *   Используем BitsAndBytes для квантования предварительно обученной модели во время ее загрузки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Настройка окружения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (4.0.0)\n",
      "Requirement already satisfied: bitsandbytes in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (0.48.2)\n",
      "Requirement already satisfied: trl in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (0.23.1)\n",
      "Requirement already satisfied: filelock in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (0.34.4)\n",
      "Requirement already satisfied: packaging in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from bitsandbytes) (2.9.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.5.1)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from trl) (1.10.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from trl) (4.56.1)\n",
      "Requirement already satisfied: psutil in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (7.1.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (0.6.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.21.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from transformers>=4.56.1->trl) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Если вы используете Colab\n",
    "!pip install datasets bitsandbytes trl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если вы используете Jupyter Template от runpod.io\n",
    "#!pip install datasets bitsandbytes trl transformers peft huggingface-hub accelerate safetensors pandas matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from accelerate import init_empty_weights\n",
    "from accelerate.utils.modeling import find_tied_parameters, get_mixed_precision_context_manager\n",
    "from accelerate.utils.operations import convert_outputs_to_fp32\n",
    "from bitsandbytes.nn import Linear8bitLt, Linear4bit, LinearFP4, LinearNF4\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, AutoConfig\n",
    "from transformers.integrations.bitsandbytes import get_keys_to_not_convert\n",
    "from types import MethodType\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Цель квантования\n",
    "\n",
    " Мы квантуем модели, чтобы уменьшить их объем в памяти. Мы можем легко сократить размер модели до четверти или восьмой части от исходного размера. Однако имейте в виду, что чем сильнее квантуется модель (т.е. чем меньше бит используется для представления ее весов), тем больше вероятность отрицательного влияния на ее производительность."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Предварительные сведения о типах данных\n",
    "\n",
    " | Тип | Название | Количество бит | Псевдоним |\n",
    " |---|---|---|---|\n",
    " | FP32 | Число с плавающей запятой | 32 | Полная точность |\n",
    " | BF16 | Brain Float | 16 | Половинная точность |\n",
    " | FP16 | Число с плавающей запятой | 16 | Половинная точность |\n",
    " | INT8 | Целое число | 8 | 8-битное квантование |\n",
    " | FP4 | Число с плавающей запятой | 4 | 4-битное квантование |\n",
    " | NF4 | Normal Float | 4 | 4-битное квантование |\n",
    "\n",
    "\n",
    "\n",
    " ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_sizes.png?raw=True)\n",
    "\n",
    " <center>Рисунок 2.1 - Сравнение размеров типов данных</center>\n",
    "\n",
    "\n",
    "\n",
    " ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/model_sizes.png?raw=True)\n",
    "\n",
    " <center>Рисунок 2.2 - Представление одной и той же модели с использованием различных типов данных</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Основы квантования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.2066), tensor(0.2097))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(11)\n",
    "weights = torch.randn(1000) * .07\n",
    "weights.min(), weights.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2066, -0.1026,  0.0015,  0.1056,  0.2097]), tensor(0.1041))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_bins = 4\n",
    "bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
    "bin_width = bins[1]-bins[0]\n",
    "bins, bin_width\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "counts, _, _ = ax.hist(weights, bins=bins)\n",
    "ax.set_xlabel('Значения')\n",
    "ax.set_title('Использование четырех интервалов')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
      "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
      "         0.0174,  0.1101, -0.1148, -0.1115])\n",
      "tensor([1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 3, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
    "print(weights[:20])\n",
    "print(bin_indexes[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "counts, _, _ = ax.hist(bin_indexes, bins=np.arange(n_bins+1)-.5)\n",
    "ax.set_xticks([0, 1, 2, 3])\n",
    "ax.set_xlabel('Индексы интервалов')\n",
    "ax.set_title('Использование четырех интервалов')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " $$\n",
    "\n",
    " \\Large\n",
    "\n",
    " \\text{n_bins}=2^{\\text{n_bits}} \\implies \\text{n_bits} = \\log_2({\\text{n_bins}})\n",
    "\n",
    " $$\n",
    "\n",
    "\n",
    "\n",
    " <center>Уравнение 2.1 - Количество бит в зависимости от количества интервалов</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_values = bins[:-1]\n",
    "first_bin = bin_values[0]\n",
    "bin_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    " $$\n",
    "\n",
    " \\Large\n",
    "\n",
    " \\text{approx_value} = \\text{bin_index} * \\text{bin_width} + \\text{first_bin}\n",
    "\n",
    " $$\n",
    "\n",
    "\n",
    "\n",
    " <center>Уравнение 2.2 - Восстановление (приближенного) исходного значения</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, n_bins) * bin_width + first_bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066,  0.0015, -0.1026,\n",
      "        -0.1026, -0.1026,  0.1056, -0.1026,  0.0015,  0.0015, -0.1026, -0.1026,\n",
      "         0.0015,  0.1056, -0.2066, -0.2066])\n"
     ]
    }
   ],
   "source": [
    "approx_values = bin_indexes * bin_width + first_bin\n",
    "print(approx_values[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
      "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
      "         0.0174,  0.1101, -0.1148, -0.1115])\n"
     ]
    }
   ],
   "source": [
    "print(weights[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0615)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "mse_fn = nn.MSELoss()\n",
    "mse_fn(approx_values, weights).sqrt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(weights, n_bits=8):\n",
    "    assert n_bits <= 16, \"Использование большего количества бит может привести к очень медленному выполнению и/или сбоям.\"\n",
    "    n_bins = 2**n_bits\n",
    "    bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
    "    first_bin = bins[0]\n",
    "    bin_width = bins[1]-bins[0]\n",
    "    bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
    "    return bin_indexes, bin_width, first_bin\n",
    "\n",
    "def dequantize(bin_indexes, bin_width, first_bin):\n",
    "    approx_values = bin_indexes * bin_width + first_bin\n",
    "    return approx_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-битное квантование:\n",
      "tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066])\n",
      "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
      "tensor(0.0615)\n",
      "\n",
      "\n",
      "4-битное квантование:\n",
      "tensor([-0.0505,  0.0535, -0.0505,  0.0015, -0.0245, -0.1286])\n",
      "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
      "tensor(0.0152)\n",
      "\n",
      "\n",
      "8-битное квантование:\n",
      "tensor([-0.0359,  0.0714, -0.0261,  0.0080, -0.0131, -0.1058])\n",
      "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
      "tensor(0.0010)\n",
      "\n",
      "\n",
      "16-битное квантование:\n",
      "tensor([-0.0359,  0.0718, -0.0248,  0.0085, -0.0128, -0.1049])\n",
      "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
      "tensor(0.0001)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_bits in [2, 4, 8, 16]:\n",
    "    res = quantize(weights, n_bits=n_bits)\n",
    "    approx_values = dequantize(*res)\n",
    "    print(f'{n_bits}-битное квантование:')\n",
    "    print(approx_values[:6])\n",
    "    print(weights[:6])\n",
    "    print(mse_fn(approx_values, weights).sqrt())\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ****\n",
    "\n",
    " **ОТСТУПЛЕНИЕ: Распределение весов в линейных слоях Phi-3**\n",
    "\n",
    "\n",
    "\n",
    " На следующих графиках показано распределение весов большого линейного слоя `qkv_proj` в блоке самовнимания Phi-3. Другие слои, такие как `o_proj`, также расположенные в блоке самовнимания, а также `gate_up_proj` и `down_proj` в блоке MLP, имеют очень похожее распределение весов. Этот слой присутствует в каждом из 32 блоков декодера (что указано числом в квадратных скобках). Вы заметите, что эти миллионы весов сконцентрированы в очень узком диапазоне. Однако есть и несколько выбросов, поэтому каждый подграфик также содержит фактический диапазон наблюдаемых весов в соответствующем слое.\n",
    "\n",
    "\n",
    "\n",
    " ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/self_attn.qkv_proj.png?raw=True)\n",
    "\n",
    " <center>Рисунок 2.5 - Распределение весов в слоях Phi-3</center>\n",
    "\n",
    "\n",
    "\n",
    " ****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Веса с половинной точностью (FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048],\n",
      "       dtype=torch.float16)\n",
      "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n"
     ]
    }
   ],
   "source": [
    "fp16_weights = weights.to(torch.float16)\n",
    "print(fp16_weights[:6])\n",
    "print(weights[:6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4244e-05)\n"
     ]
    }
   ],
   "source": [
    "print(mse_fn(fp16_weights, weights).sqrt())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Пограничные случаи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8526e-16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(14)\n",
    "tiny_values = torch.randn(1000)*1e-5\n",
    "fp16_tiny_values = tiny_values.to(torch.float16)\n",
    "mse_fn(fp16_tiny_values, tiny_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.7241e-06,  1.1441e-05,  3.7199e-06, -1.1252e-06, -2.4735e-08])\n",
      "tensor([-2.7418e-06,  1.1444e-05,  3.6955e-06, -1.1325e-06, -0.0000e+00],\n",
      "       dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "print(tiny_values[155:160])\n",
    "print(fp16_tiny_values[155:160])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([155074.0938,  64881.6602,   2729.5815, -40790.6562,  68846.7188])\n",
      "tensor([    inf,  64896.,   2730., -40800.,     inf], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(19)\n",
    "large_values = torch.randn(1000)*1e5\n",
    "fp16_large_values = large_values.to(torch.float16)\n",
    "print(large_values[:5])\n",
    "print(fp16_large_values[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp16_info = torch.finfo(torch.float16)\n",
    "fp16_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.960464477539063e-08"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smallest_subnormal = fp16_info.smallest_normal * 2**-10\n",
    "smallest_subnormal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Brain Float (BF16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)\n",
      "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)\n"
     ]
    }
   ],
   "source": [
    "bf16_info = torch.finfo(torch.bfloat16)\n",
    "print(bf16_info)\n",
    "print(fp16_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp32_info = torch.finfo(torch.float32)\n",
    "fp32_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.555555582])\n",
      "tensor([0.555664062], dtype=torch.float16)\n",
      "tensor([0.554687500], dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([0.555555555])\n",
    "torch.set_printoptions(precision=9)\n",
    "print(x)\n",
    "print(x.to(torch.float16))\n",
    "print(x.to(torch.bfloat16))\n",
    "torch.set_printoptions(precision=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " | Тип | Точность | Субнормальные | Мин. | Макс. |\n",
    " |---|---|---|---|---|\n",
    " | FP32 | e-08 | e-45 | e-38 | e+38 |\n",
    " | BF16 | e-03  | Н/Д | e-38 | e+38 |\n",
    " | FP16 | e-04  | e-08  | e-05 | e+04 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Загрузка моделей\n",
    "\n",
    " ****\n",
    "\n",
    " **Итог раздела \"Загрузка моделей\"**\n",
    "\n",
    " *   Если ваш GPU поддерживает, используйте `torch.bfloat16` вместо `torch.float16` для всех операций с 16-битной точностью.\n",
    "\n",
    "     ```python\n",
    "     supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
    "     dtypes16 = (torch.bfloat16 if supported else torch.float16)\n",
    "     ```\n",
    "\n",
    " *   При загрузке предварительно обученной модели всегда явно указывайте `torch_dtype`.\n",
    "\n",
    "     ```python\n",
    "     model = AutoModelForCausalLM.from_pretrained(repo_id, device_map='cuda:0', torch_dtype=torch.float32)\n",
    "     ```\n",
    "\n",
    " ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parm_dtypes(iterable, top_k=3):\n",
    "    return Counter([p.dtype for p in iterable]).most_common(top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages/huggingface_hub/file_download.py:982: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54daa711244f4e9a84ead01e5636537c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1324.785664\n",
      "[(torch.float32, 388)]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Download entire repository\n",
    "snapshot_download(\n",
    "    repo_id=\"facebook/opt-350m\",\n",
    "    local_dir=\"./opt-350m-model\",\n",
    "    ignore_patterns=[\"*.h5\", \"*.ot\", \"*.msgpack\"],  # Skip unnecessary formats\n",
    "    local_dir_use_symlinks=False\n",
    ")\n",
    "\n",
    "# Load from local directory\n",
    "model_dir = \"./opt-350m-model\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir, device_map='cuda:0')\n",
    "print(model.get_memory_footprint()/1e6)   \n",
    "print(get_parm_dtypes(model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/facebook/opt-350m/resolve/main/pytorch_model.bin\n",
    "# !ls -la pytorch_model.bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(torch.float16, 388)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('opt-350m-model/pytorch_model.bin')\n",
    "get_parm_dtypes(iter(state_dict.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_dir, \n",
    "                                             device_map='cuda:0',\n",
    "                                             torch_dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "batch = tokenizer(['This is a simple test'], return_tensors='pt')\n",
    "batch['labels'] = batch['input_ids']\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8001, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(**batch)\n",
    "out.loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Модели с половинной точностью (16 бит)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.bfloat16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
    "dtype16 = (torch.bfloat16 if supported else torch.float16)\n",
    "dtype16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662.392832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(torch.bfloat16, 388)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(dtype16)\n",
    "print(model.get_memory_footprint()/1e6)\n",
    "get_parm_dtypes(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662.392832\n",
      "[(torch.bfloat16, 388)]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_dir, \n",
    "                                             device_map='cuda:0',\n",
    "                                             torch_dtype=dtype16)\n",
    "print(model.get_memory_footprint()/1e6)\n",
    "print(get_parm_dtypes(model.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7930, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(**batch)\n",
    "out.loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Смешанная точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedModel(nn.Module):\n",
    "    def __init__(self, dtype):\n",
    "        super().__init__()\n",
    "        self.a = nn.Linear(1000, 1000, dtype=dtype)\n",
    "        self.b = nn.Linear(1000, 1000, dtype=dtype)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.b(self.a(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixedModel(\n",
       "  (a): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (b): Linear(in_features=1000, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed32 = MixedModel(torch.float32)\n",
    "mixed32.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121 μs ± 204 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixedModel(\n",
       "  (a): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  (b): Linear(in_features=1000, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed16 = MixedModel(torch.float16)\n",
    "mixed16.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.2 μs ± 6.19 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mixed16(torch.randn(1000, 1000, dtype=torch.float16, device='cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.4 μs ± 3.82 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "    %timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "    res16 = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
    "    \n",
    "res32 = res16.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocast_context = torch.autocast(device_type=\"cuda\", dtype=torch.float16)\n",
    "# исходный метод forward\n",
    "model_forward_func = mixed32.forward.__func__\n",
    "# оборачиваем метод контекстным менеджером\n",
    "new_forward = autocast_context(model_forward_func)\n",
    "# присваиваем обернутый метод обратно модели\n",
    "mixed32.forward = MethodType(new_forward, mixed32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
    "res.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed32.forward = MethodType(convert_outputs_to_fp32(mixed32.forward.__func__), mixed32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n",
    "res.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.8 μs ± 9.49 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cuda'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Библиотека BitsAndBytes\n",
    "\n",
    " [BitsAndBytes](https://huggingface.co/docs/bitsandbytes/main/en/index) — это основной пакет для квантования. Из его документации:\n",
    "\n",
    "\n",
    "\n",
    " \"*bitsandbytes обеспечивает доступ к большим языковым моделям посредством k-битного квантования для PyTorch. bitsandbytes предоставляет три основные функции для значительного снижения потребления памяти при выводе и обучении:*\n",
    "\n",
    "\n",
    "\n",
    " *   *8-битные оптимизаторы используют блочное квантование для сохранения 32-битной производительности при малой доле стоимости памяти.*\n",
    "\n",
    " *   *LLM.Int() или 8-битное квантование позволяет выполнять вывод больших языковых моделей, используя только половину необходимой памяти и без какого-либо ухудшения производительности. Этот метод основан на по-векторном квантовании для квантования большинства признаков в 8 бит и отдельной обработке выбросов с помощью 16-битного матричного умножения.*\n",
    "\n",
    " *   *QLoRA или 4-битное квантование позволяет обучать большие языковые модели с использованием нескольких методов экономии памяти, которые не компрометируют производительность. Этот метод квантует модель до 4 бит и вставляет небольшой набор обучаемых весов низкоранговой адаптации (LoRA), чтобы обеспечить обучение.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BitsAndBytesConfig {\n",
       "  \"_load_in_4bit\": false,\n",
       "  \"_load_in_8bit\": false,\n",
       "  \"bnb_4bit_compute_dtype\": \"float32\",\n",
       "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "  \"bnb_4bit_quant_type\": \"fp4\",\n",
       "  \"bnb_4bit_use_double_quant\": false,\n",
       "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "  \"llm_int8_has_fp16_weight\": false,\n",
       "  \"llm_int8_skip_modules\": null,\n",
       "  \"llm_int8_threshold\": 6.0,\n",
       "  \"load_in_4bit\": false,\n",
       "  \"load_in_8bit\": false,\n",
       "  \"quant_method\": \"bitsandbytes\"\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig()\n",
    "bnb_config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 8-битное квантование\n",
    "\n",
    " \"*LLM.int8() — это метод квантования, который не снижает производительность, что делает вывод больших моделей более доступным. Ключевая идея заключается в извлечении выбросов из входных данных и весов и их умножении в 16-битном формате. Все остальные значения умножаются в 8-битном формате и квантуются в Int8 перед тем, как быть деквантованными обратно в 16 бит. Результаты 16-битного и 8-битного умножения объединяются для получения окончательного выхода.*\"\n",
    "\n",
    "\n",
    "\n",
    " Источник: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)\n",
    "\n",
    "\n",
    "\n",
    " ****\n",
    "\n",
    " **Итог раздела \"8-битное квантование\"**\n",
    "\n",
    " *   Загрузите 8-битную квантованную модель несколькими строками кода:\n",
    "\n",
    "     ```python\n",
    "\n",
    "     bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "     model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
    "\n",
    "                                                  device_map='cuda:0',\n",
    "\n",
    "                                                  torch_dtype=torch.float32,\n",
    "\n",
    "                                                  quantization_config=bnb_config)\n",
    "\n",
    "     ```\n",
    "\n",
    "     *   Квантование изменяет тип по умолчанию неквантованных слоев на `torch.float16`, если мы явно не предоставим аргумент `torch_dtype` при вызове метода `from_pretrained()`.\n",
    "\n",
    " *   8-битное квантование заменяет все линейные слои, кроме:\n",
    "\n",
    "     *   слоев со связанными (общими) весами;\n",
    "\n",
    "     *   последнего слоя модели;\n",
    "\n",
    "     *   любого слоя с именем `lm_head`.\n",
    "\n",
    " *   Если вы хотите пропустить дополнительные модули, используйте аргумент конфигурации `llm_int8_skip_modules` и обязательно включите вручную слои со связанными весами, чтобы избежать ошибок.\n",
    "\n",
    " *   Вычисления (внутри квантованных слоев) происходят в `torch.float16`.\n",
    "\n",
    " ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359.354368\n",
      "[(torch.float16, 242), (torch.int8, 146)]\n"
     ]
    }
   ],
   "source": [
    "bnb_config_q8 = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model_q8 = AutoModelForCausalLM.from_pretrained(model_dir,\n",
    "                                                device_map='cuda:0',\n",
    "                                                quantization_config=bnb_config_q8)\n",
    "print(model_q8.get_memory_footprint()/1e6)\n",
    "print(get_parm_dtypes(model_q8.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8339, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Возможно, вы не получите NaN, это зависит от среды\n",
    "out = model_q8(**batch)\n",
    "out.loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415.670272\n",
      "[(torch.float32, 242), (torch.int8, 146)]\n"
     ]
    }
   ],
   "source": [
    "model_q8_32 = AutoModelForCausalLM.from_pretrained(model_dir, \n",
    "                                                device_map='cuda:0',\n",
    "                                                quantization_config=bnb_config_q8,\n",
    "                                                torch_dtype=torch.float32)\n",
    "print(model_q8_32.get_memory_footprint()/1e6)\n",
    "print(get_parm_dtypes(model_q8_32.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loschilov_aa/.conda/envs/pytorchbook/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:181: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.8012, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model_q8_32(**batch)\n",
    "out.loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Квантованные линейные слои"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTDecoderLayer(\n",
       "  (self_attn): OPTAttention(\n",
       "    (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
       "    (v_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
       "    (q_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
       "    (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (activation_fn): ReLU()\n",
       "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n",
       "  (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n",
       "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_layer = model_q8_32.model.decoder.layers[0]\n",
    "dec_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear8bitLt(in_features=1024, out_features=1024, bias=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q8_layer = dec_layer.self_attn.k_proj\n",
    "q8_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ -67, -113,  -89,  ...,   65,  -16,  -87],\n",
       "                      [  60,  120,   90,  ...,  -50,   32,   80],\n",
       "                      [  47,  127,   86,  ...,  -34,    8,   90],\n",
       "                      ...,\n",
       "                      [ -65,   65,   34,  ...,  -64,   35,   64],\n",
       "                      [  57,   67,   21,  ...,   63,  -64,  -64],\n",
       "                      [ -64,   63,  -11,  ...,  -64,   34,   63]], device='cuda:0',\n",
       "                     dtype=torch.int8)),\n",
       "             ('bias',\n",
       "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
       "                     device='cuda:0')),\n",
       "             ('SCB',\n",
       "              tensor([0.1250, 0.1252, 0.1250,  ..., 0.1252, 0.1250, 0.1254], device='cuda:0')),\n",
       "             ('weight_format', tensor(0, dtype=torch.uint8))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q8_state = q8_layer.state_dict()\n",
    "q8_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(50272, 512, padding_idx=1)\n",
      "Linear(in_features=512, out_features=50272, bias=False)\n"
     ]
    }
   ],
   "source": [
    "print(model.model.decoder.embed_tokens)\n",
    "print(model.lm_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(model.model.decoder.embed_tokens.weight, \n",
    "               model.lm_head.weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, [['lm_head.weight', 'model.decoder.embed_tokens.weight']])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained('facebook/opt-350m')\n",
    "\n",
    "config.tie_word_embeddings, find_tied_parameters(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(..., device='meta', size=(50272, 512), dtype=torch.float16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with init_empty_weights(): # загружает только мета-тензоры\n",
    "    empty_model = AutoModelForCausalLM.from_config(config)\n",
    "\n",
    "empty_model.lm_head.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.decoder.embed_tokens', 'lm_head']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_modules = get_keys_to_not_convert(empty_model)\n",
    "skip_modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.decoder.embed_tokens: torch.float32\n",
      "lm_head: torch.float32\n"
     ]
    }
   ],
   "source": [
    "for module in skip_modules:\n",
    "    print(f'{module}: {next(model_q8_32.get_submodule(module).parameters()).dtype}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Параметр `llm_int8_skip_modules`\n",
    "\n",
    " Если у вашей модели есть связанные веса, и вы решили использовать собственный список модулей для пропуска, вы должны добавить один из связанных слоев в свой список. Если вы этого не сделаете, может возникнуть следующее исключение:\n",
    "\n",
    "\n",
    "\n",
    " ***\n",
    "\n",
    " `AttributeError: 'Parameter' object has no attribute 'SCB'`\n",
    "\n",
    " ***\n",
    "\n",
    "\n",
    "\n",
    " ```python\n",
    "\n",
    " # Эта конфигурация ВЫЗОВЕТ исключение\n",
    "\n",
    " # при попытке загрузить веса для связанного слоя\n",
    "\n",
    " # bnb_config_skip = BitsAndBytesConfig(load_in_8bit=True,\n",
    "\n",
    " #                                      llm_int8_skip_modules=['o_proj'])\n",
    "\n",
    "\n",
    "\n",
    " # Эта конфигурация работает нормально, потому что\n",
    "\n",
    " # связанный слой, lm_head, находится в списке\n",
    "\n",
    " bnb_config_skip = BitsAndBytesConfig(\n",
    "\n",
    "         load_in_8bit=True,\n",
    "\n",
    "         llm_int8_skip_modules=['o_proj', 'lm_head'])\n",
    "\n",
    "\n",
    "\n",
    " model_skip = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
    "\n",
    "                                                   device_map='cuda:0',\n",
    "\n",
    "                                                   torch_dtype=torch.float32,\n",
    "\n",
    "                                                   quantization_config=bnb_config_skip)\n",
    "\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### 8-битные слои\n",
    "\n",
    " \"*Чтобы квантовать линейный слой, следует сначала загрузить исходные веса fp16 / bf16 в модуль Linear8bitLt, затем вызвать int8_module.to(\"cuda\") для квантования весов fp16.*\"\n",
    "\n",
    "\n",
    "\n",
    " Источник: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.2220, -0.0085,  0.3072, -0.2097,  0.0531,  0.1224,  0.0525, -0.2350,\n",
       "                        0.0456,  0.2687],\n",
       "                      [-0.1459,  0.1786, -0.1443, -0.0233,  0.1689,  0.0015, -0.2514,  0.1644,\n",
       "                        0.1920,  0.1678],\n",
       "                      [ 0.2346,  0.1411,  0.2128,  0.0519,  0.2147, -0.2786, -0.0433, -0.0364,\n",
       "                       -0.1504,  0.0823],\n",
       "                      [ 0.2388, -0.2134, -0.1620, -0.1023,  0.2433, -0.2680,  0.3099, -0.1933,\n",
       "                       -0.0471, -0.0391],\n",
       "                      [-0.1273,  0.2197, -0.0136, -0.1938, -0.1746,  0.0404,  0.0711, -0.1730,\n",
       "                        0.0539, -0.1992],\n",
       "                      [-0.0051,  0.1373, -0.0267, -0.0907, -0.0107,  0.1108, -0.1566,  0.0172,\n",
       "                        0.2075, -0.0028],\n",
       "                      [ 0.2082, -0.2857, -0.2640, -0.1436,  0.1704,  0.1908, -0.2350,  0.1187,\n",
       "                       -0.0568,  0.0916],\n",
       "                      [ 0.2974, -0.3061,  0.0559,  0.1899,  0.0265, -0.1893, -0.0582, -0.0943,\n",
       "                        0.2451,  0.2825],\n",
       "                      [-0.1241, -0.3106, -0.1002, -0.1745,  0.2693,  0.2985,  0.1633, -0.0270,\n",
       "                       -0.3049,  0.0227],\n",
       "                      [-0.1217,  0.0035, -0.1481, -0.0330,  0.1787,  0.3123,  0.2600, -0.1720,\n",
       "                        0.2059,  0.2057]])),\n",
       "             ('bias',\n",
       "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
       "                       0.0653, -0.0854]))])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = 10\n",
    "n_out = 10\n",
    "\n",
    "torch.manual_seed(11)\n",
    "fp_layer = nn.Linear(n_in, n_out)\n",
    "\n",
    "int8_layer = Linear8bitLt(n_in, n_out, has_fp16_weights=False)\n",
    "\n",
    "int8_layer.load_state_dict(fp_layer.state_dict())\n",
    "int8_layer.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ -92,   -4,  127,  -87,   22,   51,   22,  -97,   19,  111],\n",
       "                      [ -74,   90,  -73,  -12,   85,    1, -127,   83,   97,   85],\n",
       "                      [ 107,   64,   97,   24,   98, -127,  -20,  -17,  -69,   38],\n",
       "                      [  98,  -87,  -66,  -42,  100, -110,  127,  -79,  -19,  -16],\n",
       "                      [ -74,  127,   -8, -112, -101,   23,   41, -100,   31, -115],\n",
       "                      [  -3,   84,  -16,  -56,   -7,   68,  -96,   11,  127,   -2],\n",
       "                      [  93, -127, -117,  -64,   76,   85, -104,   53,  -25,   41],\n",
       "                      [ 123, -127,   23,   79,   11,  -79,  -24,  -39,  102,  117],\n",
       "                      [ -51, -127,  -41,  -71,  110,  122,   67,  -11, -125,    9],\n",
       "                      [ -50,    1,  -60,  -13,   73,  127,  106,  -70,   84,   84]],\n",
       "                     device='cuda:0', dtype=torch.int8)),\n",
       "             ('bias',\n",
       "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
       "                       0.0653, -0.0854], device='cuda:0')),\n",
       "             ('SCB',\n",
       "              tensor([0.3071, 0.2515, 0.2786, 0.3098, 0.2197, 0.2075, 0.2856, 0.3062, 0.3105,\n",
       "                      0.3123], device='cuda:0')),\n",
       "             ('weight_format', tensor(0, dtype=torch.uint8))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int8_layer = int8_layer.to(0) # Квантование происходит здесь\n",
    "int8_state = int8_layer.state_dict()\n",
    "int8_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 4-битное квантование\n",
    "\n",
    " \"*QLoRA — это метод тонкой настройки, который квантует модель до 4 бит и добавляет набор весов низкоранговой адаптации (LoRA) к модели, настраивая их через квантованные веса. Этот метод также вводит новый тип данных — 4-битный NormalFloat (LinearNF4) в дополнение к стандартному типу данных Float4 (LinearFP4). LinearNF4 — это тип данных квантования для нормально распределенных данных и может улучшить производительность.*\"\n",
    "\n",
    " Источник: [4-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear4bit)\n",
    "\n",
    " ****\n",
    " \n",
    " **Итог раздела \"4-битное квантование\"**\n",
    "\n",
    " *   Максимально эффективно используйте 4-битную квантованную модель, применяя тип normal float (NF4) и двойное квантование.\n",
    "\n",
    "     ```python\n",
    "\n",
    "     supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
    "\n",
    "     compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
    "\n",
    "     nf4_config = BitsAndBytesConfig(\n",
    "\n",
    "        load_in_4bit=True,\n",
    "\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "\n",
    "        bnb_4bit_compute_dtype=compute_dtype\n",
    "\n",
    "     )\n",
    "\n",
    "     model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
    "\n",
    "                                                  device_map='cuda:0',\n",
    "\n",
    "                                                  torch_dtype=torch.float32,\n",
    "\n",
    "                                                  quantization_config=nf4_config)\n",
    "\n",
    "     ```\n",
    "\n",
    " *   Вычисления (внутри квантованных слоев) происходят в указанном типе (`bnb_4bit_compute_dtype`):\n",
    "\n",
    "     FP32 лучше, чем BF16, который лучше, чем FP16.\n",
    "\n",
    " ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
    "compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=compute_dtype\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Скрытая жизнь типов данных (`Dtypes`)**\n",
    "\n",
    " | Обычная модель | Квантованная модель |\n",
    " |---|---|\n",
    " | ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_regular.png?raw=True) | ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_qt.png?raw=True) |\n",
    " | <center>Рисунок 2.6 - Поток типов данных в обычной модели</center> | <center>Рисунок 2.7 - Поток типов данных в квантованной модели</center> |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264.15104\n",
      "[(torch.float32, 242), (torch.uint8, 146)]\n"
     ]
    }
   ],
   "source": [
    "model_q4 = AutoModelForCausalLM.from_pretrained(model_dir, \n",
    "                                                device_map='cuda:0',\n",
    "                                                torch_dtype=torch.float32,\n",
    "                                                quantization_config=nf4_config)\n",
    "print(model_q4.get_memory_footprint()/1e6)\n",
    "print(get_parm_dtypes(model_q4.parameters()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.7086, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model_q4(**batch)\n",
    "out.loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTDecoderLayer(\n",
       "  (self_attn): OPTAttention(\n",
       "    (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "    (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "    (q_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "    (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (activation_fn): ReLU()\n",
       "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
       "  (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
       "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_layer = model_q4.model.decoder.layers[0]\n",
    "dec_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear4bit(in_features=1024, out_features=1024, bias=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q4_layer = dec_layer.self_attn.k_proj\n",
    "q4_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[ 32],\n",
       "                      [ 29],\n",
       "                      [208],\n",
       "                      ...,\n",
       "                      [ 66],\n",
       "                      [ 34],\n",
       "                      [172]], device='cuda:0', dtype=torch.uint8)),\n",
       "             ('bias',\n",
       "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
       "                     device='cuda:0')),\n",
       "             ('weight.absmax',\n",
       "              tensor([230, 230,  30,  ...,   1,  26, 191], device='cuda:0',\n",
       "                     dtype=torch.uint8)),\n",
       "             ('weight.quant_map',\n",
       "              tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
       "                       0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
       "                     device='cuda:0')),\n",
       "             ('weight.nested_absmax',\n",
       "              tensor([0.0077, 0.0142, 0.0153, 0.0138, 0.0399, 0.0409, 0.0417, 0.0426, 0.0053,\n",
       "                      0.0053, 0.0053, 0.0053, 0.0051, 0.0051, 0.0051, 0.0053, 0.0195, 0.0269,\n",
       "                      0.0223, 0.0195, 0.0053, 0.0053, 0.0054, 0.0054, 0.0317, 0.0315, 0.0306,\n",
       "                      0.0320, 0.0262, 0.0265, 0.0230, 0.0296, 0.0051, 0.0065, 0.0050, 0.0050,\n",
       "                      0.0051, 0.0053, 0.0050, 0.0051, 0.0056, 0.0056, 0.0056, 0.0056, 0.0428,\n",
       "                      0.0410, 0.0405, 0.0422, 0.0397, 0.0402, 0.0394, 0.0414, 0.0204, 0.0106,\n",
       "                      0.0140, 0.0078, 0.0406, 0.0349, 0.0359, 0.0418, 0.0503, 0.0499, 0.0470,\n",
       "                      0.0458], device='cuda:0')),\n",
       "             ('weight.nested_quant_map',\n",
       "              tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
       "                      -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
       "                      -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
       "                      -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
       "                      -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
       "                      -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
       "                      -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
       "                      -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
       "                      -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
       "                      -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
       "                      -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
       "                      -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
       "                      -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
       "                      -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
       "                      -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
       "                      -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
       "                      -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
       "                      -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
       "                      -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
       "                      -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
       "                      -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
       "                      -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
       "                      -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
       "                      -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
       "                      -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
       "                      -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
       "                       7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
       "                       1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
       "                       7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
       "                       2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
       "                       5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
       "                       8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
       "                       1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
       "                       2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
       "                       4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
       "                       5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
       "                       7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
       "                       8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
       "                       9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
       "                       1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
       "                       2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
       "                       3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
       "                       3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
       "                       4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
       "                       5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
       "                       5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
       "                       6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
       "                       7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
       "                       7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
       "                       8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
       "                       9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
       "                       1.0000e+00], device='cuda:0')),\n",
       "             ('weight.quant_state.bitsandbytes__nf4',\n",
       "              tensor([123,  34, 113, 117,  97, 110, 116,  95, 116, 121, 112, 101,  34,  58,\n",
       "                       32,  34, 110, 102,  52,  34,  44,  32,  34,  98, 108, 111,  99, 107,\n",
       "                      115, 105, 122, 101,  34,  58,  32,  54,  52,  44,  32,  34, 100, 116,\n",
       "                      121, 112, 101,  34,  58,  32,  34, 102, 108, 111,  97, 116,  51,  50,\n",
       "                       34,  44,  32,  34, 115, 104,  97, 112, 101,  34,  58,  32,  91,  49,\n",
       "                       48,  50,  52,  44,  32,  49,  48,  50,  52,  93,  44,  32,  34, 110,\n",
       "                      101, 115, 116, 101, 100,  95,  98, 108, 111,  99, 107, 115, 105, 122,\n",
       "                      101,  34,  58,  32,  50,  53,  54,  44,  32,  34, 110, 101, 115, 116,\n",
       "                      101, 100,  95, 100, 116, 121, 112, 101,  34,  58,  32,  34, 102, 108,\n",
       "                      111,  97, 116,  51,  50,  34,  44,  32,  34, 110, 101, 115, 116, 101,\n",
       "                      100,  95, 111, 102, 102, 115, 101, 116,  34,  58,  32,  48,  46,  49,\n",
       "                       49,  57,  57,  56,  49,  55,  50,  49,  48,  52,  51,  53,  56,  54,\n",
       "                       55,  51, 125], dtype=torch.uint8))])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q4_layer.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Сравнение слоев FP4 и NF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=10, bias=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = 10\n",
    "n_out = 10\n",
    "torch.manual_seed(11)\n",
    "fp16_layer = nn.Linear(n_in, n_out)\n",
    "fp16_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp4_layer = LinearFP4(n_in, n_out)\n",
    "fp4_layer.load_state_dict(fp16_layer.state_dict())\n",
    "\n",
    "nf4_model = LinearNF4(n_in, n_out)\n",
    "nf4_model.load_state_dict(fp16_layer.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0000,  0.0052,  0.6667,  1.0000,  0.3333,  0.5000,  0.1667,  0.2500,\n",
       "          0.0000, -0.0052, -0.6667, -1.0000, -0.3333, -0.5000, -0.1667, -0.2500],\n",
       "        device='cuda:0'),\n",
       " torch.Size([50, 1]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp4_layer = fp4_layer.to(0) # Квантование происходит здесь\n",
    "fp4_state = fp4_layer.state_dict()\n",
    "\n",
    "fp4_state['weight.quant_map'], fp4_state['weight'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Квантование FP4')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
    "ax.scatter(x=sorted(fp4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Квантование FP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
       "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
       "        device='cuda:0'),\n",
       " torch.Size([50, 1]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf4_model = nf4_model.to(0) # Квантование происходит здесь\n",
    "nf4_state = nf4_model.state_dict()\n",
    "\n",
    "nf4_state['weight.quant_map'], nf4_state['weight'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Квантование NF4')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x50 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
    "ax.scatter(x=sorted(nf4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
    "ax.set_yticks([])\n",
    "ax.set_title('Квантование NF4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Что ждет в книге \"Fine-Tuning LLMs\"\n",
    "\n",
    " Поскольку огромные линейные слои заменяются их квантованными версиями для уменьшения объема памяти модели, возникает новая проблема. Эти квантованные слои нельзя легко обновить, что делает тонкую настройку почти невозможной. Может ли новый вид слоя стать решением этой загадки? Узнайте в следующей увлекательной главе книги \"Fine-Tuning LLMs\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
